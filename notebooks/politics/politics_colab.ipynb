{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NancyFulda/towards-neural-programming-interfaces/blob/master/notebooks/politics/politics_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDrpvhHvEiBm"
      },
      "source": [
        "# Python Notebook training NPI on political views\n",
        "\n",
        "This notebook is also an example on how to use the NPI project to train your own NPI in a way that can affect GPT2's sentiment or emotion. This notebook attempts to train the GPT2 model with NPI to possess a specific political view."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2wEFrcBEiBq"
      },
      "source": [
        "## Setup\n",
        "\n",
        "### Prerequisite setup:\n",
        "\n",
        "*   Ensure you selected a runtime with a GPU. You can do that by clicking Runtime -> Change runtime type ->  Hardware Accelerator -> GPU\n",
        "*   After running the setup code in this section, restart the runtime by clicking Runtime -> Restart runtime.\n",
        "\n",
        "After you have done the prerequisite setup, you will not need to rerun this section again.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NancyFulda/towards-neural-programming-interfaces.git\n",
        "!cd towards-neural-programming-interfaces && ./install_dependencies.sh"
      ],
      "metadata": {
        "id": "8tnQFi2DEqge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the NewB news source dataset\n",
        "!git clone https://github.com/JerryWei03/NewB.git"
      ],
      "metadata": {
        "id": "uuOj-3SyFNBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Post setup\n",
        "\n",
        "***Note: You will need to restart the runtime on Colab to continue***\n",
        "\n",
        "Click on Runtime -> Restart Runtime to do so.\n"
      ],
      "metadata": {
        "id": "7-Q2yk4kGLnX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8vYjqYt4EiBs"
      },
      "outputs": [],
      "source": [
        "# For dev purposes, enable autoreload of modules\n",
        "%load_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6AxvkhH3EiBu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "%autoreload\n",
        "\n",
        "# Constructing training dataset\n",
        "from npi.dataset import NPIDatasetConstructor, NPIDatasetLoader\n",
        "\n",
        "# Models\n",
        "from npi.models import NPITrainingModels\n",
        "\n",
        "# Training NPI\n",
        "from npi.training import NPIStyleTrainer, NPITrainer\n",
        "\n",
        "# Configuration\n",
        "from npi.config import NPIConfig\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that each step in training an NPI is conditioned on the variable toggles, so you can disable certain steps to not redo them again when running the whole notebook."
      ],
      "metadata": {
        "id": "PBynmrGsJqt3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nV6-eOMoEiBu"
      },
      "outputs": [],
      "source": [
        "# Toggle steps\n",
        "construct = True\n",
        "train_class = True\n",
        "test_class = True\n",
        "train_npi = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is where an NPIConfig object is defined. It holds configuration for the NPI that you can use for the different NPI training steps. Notice that it is injected intothe NPITrainingModels class. That class will load the necessary models using the configuration defined in NPIConfig."
      ],
      "metadata": {
        "id": "EPcBvsfgRRpE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Xr_mUYVNEiBv"
      },
      "outputs": [],
      "source": [
        "model_layers = [5, 11]\n",
        "\n",
        "device = torch.device(f\"cuda:0\")\n",
        "config = NPIConfig(\n",
        "    device, gpt_model=\"gpt2\", perturbation_indices=model_layers, npi_name=\"politics\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "J8qQUlUbEiBz"
      },
      "outputs": [],
      "source": [
        "# Initialize models for training and testing\n",
        "models = NPITrainingModels(\n",
        "    config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdqqaFZCEiBv"
      },
      "source": [
        "## Create Dataset\n",
        "\n",
        "### Get Data from NewB GitHub repo\n",
        "\n",
        "Note that this step will be different depending on the data you would want to train the NPI on.\n",
        "\n",
        "#### About Construct Data\n",
        "\n",
        "The key here is to give `construct_data.construct_dataset` a tuple of `(input_text, label)`.\n",
        "\n",
        "Currently, `construct_data.construct_dataset` will generate up to the `NPIConfig.num_iters` times of text from GPT based on the input text, and labels those activations with the label you assigned to the input text. This is assuming the text outputted by GPT2 was relevant to our input text.\n",
        "\n",
        "#### Limitations\n",
        "* The labels that are currently supported is just `1` and `0`. *You need to label the type of output you want the GPT2 with NPI model to create with `0`.*\n",
        "* Currently, you will need to manually stop the dataset generation if you want to end it before it goes through your input\n",
        "* If you don't have a dataset with labels, you will need to create that manually.\n",
        "* Despite your configurations for which GPT layers to modify by the NPI, this step will generate the data from all GPT layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YubiuraEiBx"
      },
      "outputs": [],
      "source": [
        "if construct:\n",
        "    with open(\"./NewB/train_orig.txt\", \"r\", newline=\"\") as f:\n",
        "        data = pd.read_csv(f, delimiter=\"\\t\", names=[\"view\", \"text\"])\n",
        "        data[\"view\"] = data[\"view\"].replace(\n",
        "            to_replace={0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1}\n",
        "        )\n",
        "        data = data[data.view != 5]\n",
        "        data = data.sample(frac=1)\n",
        "        data_iter = zip(data[\"text\"], data[\"view\"])\n",
        "        construct_data = NPIDatasetConstructor(config)\n",
        "        construct_data.construct_dataset(data_iter, 4000) # Only creating 4000 training data points \n",
        "        # TODO: setting the limit of training data points is a WIP. You can manually stop the cell to stop the dataset generation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXWpcynGEiBx"
      },
      "source": [
        "## Train classifier from Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgooQZnZEiBy"
      },
      "outputs": [],
      "source": [
        "model_loader = NPITrainingModels(config)\n",
        "dataset_loader = NPIDatasetLoader(config, target=\"style\")\n",
        "style_trainer = NPIStyleTrainer(config, class_lr=1e-5)\n",
        "classifier = None\n",
        "if train_class:\n",
        "    classifier = style_trainer.train_classifier(\n",
        "        model_loader,\n",
        "        dataset_loader,\n",
        "        num_epochs=5,\n",
        "        #continue_epoch=4,  # Set epoch of classifier to load to continue training.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz2o83DCEiBy"
      },
      "source": [
        "### Test Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EkTIcEWnEiBy",
        "outputId": "6e4a0893-7994-4113-ca95-e086a56f7a67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74786075.66666667, 0.48333333333333334)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "_, test_loader, _, _ = dataset_loader.load_train_and_test_dataloaders()\n",
        "\n",
        "classifier = model_loader.load_style_classifier() if not classifier else classifier\n",
        "# When output=True, it will log the following in models/npi_models/style_classifier_output.log:\n",
        "#   (generated text from the dataset)\n",
        "#   truth={target_label} actual={model_output}\n",
        "style_trainer.test_model(test_loader, classifier, torch.nn.BCELoss(), output=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH-dlXcQEiBz"
      },
      "source": [
        "## Training NPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6oi0MflEiB0"
      },
      "outputs": [],
      "source": [
        "num_epochs = 6\n",
        "split_ratio = 0.25\n",
        "batch_size = 5\n",
        "headstart = 0  # set at 0 for debugging\n",
        "\n",
        "if train_npi:\n",
        "    trainer = NPITrainer(config, batch_size=batch_size, headstart=headstart)\n",
        "    dataset_loader = NPIDatasetLoader(config, split_ratio=split_ratio)\n",
        "    trainer.train_adversarial_npi(models, num_epochs, dataset_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwD1OEyuEiB0"
      },
      "source": [
        "## Test NPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M76gOLwSEiB0"
      },
      "source": [
        "Using the model loader, you can directly generate NPI text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-dINaz8IEiB0",
        "outputId": "6bce590f-5510-4fea-c86f-fc5752f9493f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model: GPT 2 Vanilla: 100%|██████████| 100/100 [00:02<00:00, 36.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Original GPT2 output: 'Trump today was found'\n",
            " to have been a liar.\n",
            "\n",
            "The FBI has been investigating the Trump campaign's ties to Russia.\n",
            "\n",
            "The Trump campaign has also been accused of using the word \"radical\" in a tweet.\n",
            "\n",
            "\"I am not a fan of the idea of a \"big-screen\" movie.\n",
            "\n",
            "\"I'm not going to say that I'm going to say that I'm going to say that I'm going to say that I'm going to say that I'm going to say that I'm going to say\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "text = \"Trump today was found\"\n",
        "print(f\"\\nOriginal GPT2 output: '{text}'\\n{models.gpt2_generate_text(text)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lqAxiIa_EiB1",
        "outputId": "94875c10-9bb7-49e6-bb89-48a3daeb79c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Model: GPT2 with NPI: 100it [00:05, 18.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NPI GPT2 output: 'Trump today was found'\n",
            " to have been a liar.\n",
            "\n",
            "The FBI has been investigating the Trump campaign's ties to Russia.\n",
            "\n",
            "The Trump campaign has also been accused of using the word \"radical\" in a tweet.\n",
            "\n",
            "\"I am not a racist, I am not a racist, I am not a racist, I am not a racist, I am not a racist, I am not a racist, I am not a racist, I am not a racist, I am not a racist, I am not a racist, I am\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nNPI GPT2 output: '{text}'\\n{models.npi_generate_text(text)}\")"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "b53feeeef0abc6b71390ce5a6fde0c401718055bbb2d86de1b9dab62a8ba524e"
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 64-bit ('towards-neural-programming-interfaces-UdnRbY7B': pipenv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "politics.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}