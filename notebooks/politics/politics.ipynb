{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Notebook training NPI on political views\n",
    "\n",
    "This notebook is also a good example on how to use the NPI project to train your own NPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before starting, you would want to change the `base_path` variable. \n",
    "It should be the absolute path pointing to the towards-neural-programming-interfaces repository.\n",
    "\n",
    "Also, each step in training an NPI is conditioned on the variable toggles, so you can disable certain steps to not redo them again when running the whole notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dev purposes, enable autoreload of modules\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "%autoreload\n",
    "\n",
    "# Constructing training dataset\n",
    "from src.dataset.construct_politics_data import construct_politics_data\n",
    "\n",
    "# Training classifier\n",
    "from src.training.train_classifier import train_classifier\n",
    "\n",
    "# Testing classifier\n",
    "from src.training.test_classifier import test_classifier\n",
    "\n",
    "# Training NPI\n",
    "from src.training.train_npi import train_adversarial_NPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path variables to customize\n",
    "base_path = \"/home/cs401r/towards-neural-programming-interfaces/\"\n",
    "classifier_path = \"classifiers/layers_5_11/\"\n",
    "npi_path = \"npi_models/\"\n",
    "data_path = base_path + \"data/processed/politics/sentence_arrays\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggle steps\n",
    "construct = False\n",
    "train_class = True\n",
    "test_class = True\n",
    "train_npi = True\n",
    "test_npi = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset\n",
    "\n",
    "### Get Data from NewB GitHub repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if construct:\n",
    "    model_layers = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] \n",
    "    with open(\"NewB/train_orig.txt\", 'r', newline='') as f:\n",
    "            data = pd.read_csv(f, delimiter=\"\\t\")\n",
    "            data[\"view\"] = data[\"view\"].replace(\n",
    "                to_replace={0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1})\n",
    "            data = data[data.view != 5]\n",
    "            data = data.sample(frac=1)\n",
    "            construct_politics_data(model_layers, data, 1, \"data/politics/sentence_arrays.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifier from Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data from /home/cs401r/towards-neural-programming-interfaces/data/processed/politics/sentence_arrays.pkl_0\n",
      "Creating Classifier Model\n",
      "Classifier INIT\n",
      "Defining classifier model\n",
      "Initializing class loss\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING AFTER EPOCH ITERATIONS\n",
      "Epoch train loss history ==  [69316069.40790273, 69307794.39270517, 69301987.27781156, 69294086.19574468, 69296749.37386018, 69301251.62310031, 69306813.76291794, 69309258.05714285, 69311981.63161094, 69318422.41945289, 69295155.56960486, 69316686.47781155, 69316593.8869301, 69309779.84680851, 69325316.7756839, 69307370.03768997, 69325595.94407295, 69308618.79635258, 69299600.67598784, 69309281.90151976, 69306704.86079027, 69301859.40911855, 69293038.86200608, 69307072.75866261, 69300823.8006079, 69306708.35258359, 69301463.09057751, 69324357.3787234, 69300542.53617021, 69313220.5568389, 69303790.64316109, 69315088.45714286, 69324230.83282675, 69299087.4212766, 69309556.82431611, 69323325.4905775, 69296362.56291793, 69296584.88024317, 69290361.23039514, 69315691.52097264, 69324128.94346504, 69301967.23647417, 69312027.70577508, 69308887.65957446, 69290937.00182371, 69315891.34589666, 69312976.12158054, 69308257.90638298, 69303879.76170212, 69305752.77325228, 69309512.98237082, 69313517.40303952, 69310706.32948329, 69320185.9987842, 69305458.28085107, 69303640.44741641, 69307599.81033434, 69307912.53495441, 69314904.15075988, 69301231.1343465, 69318827.76899695, 69298227.7544073, 69305492.05106384, 69311252.32340425, 69308809.12826748, 69303361.94528875, 69308209.27902736, 69295387.4674772, 69296184.50577508, 69302015.82006079]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(classifier_path):\n",
    "        os.mkdir(classifier_path)\n",
    "if train_class:\n",
    "    args = Namespace(\n",
    "        save_file_path=classifier_path,\n",
    "        continue_epoch=100, # You can choose to continue training from an epoch\n",
    "        train_file_path_base=base_path+\"data/processed/politics/sentence_arrays\",\n",
    "        num_epochs=70,\n",
    "        batch_size=5,\n",
    "        test_freq=5,\n",
    "        save_freq=5,\n",
    "        num_pkls=35,\n",
    "        device=torch.device(\"cuda:1\"),\n",
    "        pred_inds=[5,11],\n",
    "        class_lr=1e-5\n",
    "    )\n",
    "    classifier = train_classifier(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW FILE classifiers/layers_5_11/ epoch num 100\n",
      "Creating Classifier Model\n",
      "Classifier INIT\n",
      "Defining classifier model\n",
      "-server-server-server-server-server\n",
      "truth 0.0\n",
      "yhat 0.4929727613925934\n",
      " car.\\n\\n\"I'm not sure if\n",
      "truth 1.0\n",
      "yhat 0.4929727613925934\n",
      "\\n\\nThe United States has been accused of using\n",
      "truth 0.0\n",
      "yhat 0.4929727613925934\n",
      "ACCURACY FOR TEST 35: 0.5407166123778502\n",
      ", said the team is \"very excited\" about\n",
      "truth 0.0\n",
      "yhat 0.4929727613925934\n",
      " I noticed was that the first thing I noticed was\n",
      "truth 0.0\n",
      "yhat 0.4929727613925934\n",
      " going to be able to do that.\\n\\n\n",
      "truth 1.0\n",
      "yhat 0.4929727613925934\n",
      "ACCURACY FOR TEST 36: 0.48534201954397393\n",
      "\"I think it's a good thing that we\n",
      "truth 1.0\n",
      "yhat 0.4929727613925934\n",
      " good thing that we're not doing this.\\n\n",
      "truth 1.0\n",
      "yhat 0.4929727613925934\n",
      " to do that.\\n\\n\"I think it\n",
      "truth 0.0\n",
      "yhat 0.4929727613925934\n",
      "ACCURACY FOR TEST 37: 0.44625407166123776\n",
      " number of people who have been killed in the conflict\n",
      "truth 0.0\n",
      "yhat 0.4929727613925934\n",
      " targeted.\\n\\n\"We're not going to\n",
      "truth 0.0\n",
      "yhat 0.4929727613925934\n",
      " own people.\\n\\nThe US has been accused\n",
      "truth 0.0\n",
      "yhat 0.4929727613925934\n",
      "ACCURACY FOR TEST 38: 0.5895765472312704\n",
      " think it's a good thing that we're not\n",
      "truth 1.0\n",
      "yhat 0.4929727613925934\n",
      " democratic process.\\n\\nThe government has also been\n",
      "truth 0.0\n",
      "yhat 0.4929727613925934\n",
      " been accused of using its military to support the Syrian\n",
      "truth 0.0\n",
      "yhat 0.4929727613925934\n",
      "ACCURACY FOR TEST 39: 0.5179153094462541\n",
      "done\n",
      "TOTAL ACCURACY OVERALL: 0.5159609120521174\n",
      "\n",
      "================================================\n",
      "\n",
      "NEW FILE classifiers/layers_5_11/ epoch num 170\n",
      "Creating Classifier Model\n",
      "Classifier INIT\n",
      "Defining classifier model\n",
      "-server-server-server-server-server\n",
      "truth 0.0\n",
      "yhat 0.4935724437236786\n",
      " car.\\n\\n\"I'm not sure if\n",
      "truth 1.0\n",
      "yhat 0.4935724437236786\n",
      "\\n\\nThe United States has been accused of using\n",
      "truth 0.0\n",
      "yhat 0.4935724437236786\n",
      "ACCURACY FOR TEST 35: 0.5407166123778502\n",
      ", said the team is \"very excited\" about\n",
      "truth 0.0\n",
      "yhat 0.4935724437236786\n",
      " I noticed was that the first thing I noticed was\n",
      "truth 0.0\n",
      "yhat 0.4935724437236786\n",
      " going to be able to do that.\\n\\n\n",
      "truth 1.0\n",
      "yhat 0.4935724437236786\n",
      "ACCURACY FOR TEST 36: 0.48534201954397393\n",
      "\"I think it's a good thing that we\n",
      "truth 1.0\n",
      "yhat 0.4935724437236786\n",
      " good thing that we're not doing this.\\n\n",
      "truth 1.0\n",
      "yhat 0.4935724437236786\n",
      " to do that.\\n\\n\"I think it\n",
      "truth 0.0\n",
      "yhat 0.4935724437236786\n",
      "ACCURACY FOR TEST 37: 0.44625407166123776\n",
      " number of people who have been killed in the conflict\n",
      "truth 0.0\n",
      "yhat 0.4935724437236786\n",
      " targeted.\\n\\n\"We're not going to\n",
      "truth 0.0\n",
      "yhat 0.4935724437236786\n",
      " own people.\\n\\nThe US has been accused\n",
      "truth 0.0\n",
      "yhat 0.4935724437236786\n",
      "ACCURACY FOR TEST 38: 0.5895765472312704\n",
      " think it's a good thing that we're not\n",
      "truth 1.0\n",
      "yhat 0.4935724437236786\n",
      " democratic process.\\n\\nThe government has also been\n",
      "truth 0.0\n",
      "yhat 0.4935724437236786\n",
      " been accused of using its military to support the Syrian\n",
      "truth 0.0\n",
      "yhat 0.4935724437236786\n",
      "ACCURACY FOR TEST 39: 0.5179153094462541\n",
      "done\n",
      "TOTAL ACCURACY OVERALL: 0.5159609120521174\n",
      "\n",
      "================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if test_class:\n",
    "    args = Namespace(\n",
    "        model_dir_path=classifier_path,\n",
    "        data_path=data_path,\n",
    "        test_pkls=\"35,36,37,38,39\",\n",
    "        test_epochs=\"100,170\",\n",
    "        perturbation_indices=\"5,11\"\n",
    "    )\n",
    "    test_classifier(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training NPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "<<<        USING THE FOLLOWING INPUT ARGUMENTS!!!        >>>\n",
      "Namespace(batch_size=5, content_classifier_path='classifiers/layers_5_11/Classifier_classification_network_epoch50.bin', content_classifier_type='pretrained', device=device(type='cuda'), disc_lr=0.0001, discrim_coeff=3.0, generation_classifier_type='adversarial', head_start_num=5, language_model_type='gpt2', max_seq_len=10, n_gpu=2, npi_lr=0.0001, npi_type='adversarial', num_epochs=60, num_pkls=35, num_seq_iters=10, perturbation_indices=[5, 11], save_file_path='npi_models/params_discco3.0_styco10.0_simco1.0_layers_5_11/', save_freq=5, similarity_coeff=1.0, style_coeff=10.0, test_freq=5, train_file_path='/home/cs401r/towards-neural-programming-interfaces/data/processed/politics/sentence_arrays')\n",
      "############################################################\n",
      "############################################################\n",
      "<<<  NOTE :  ONLY FIRST 35 FILES IN DATA SET BEING USED  >>>\n",
      "############################################################\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'gpu_num'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m args \u001b[38;5;241m=\u001b[39m Namespace(\n\u001b[1;32m      3\u001b[0m     save_file_path\u001b[38;5;241m=\u001b[39mnpi_path,\n\u001b[1;32m      4\u001b[0m     train_file_path\u001b[38;5;241m=\u001b[39mdata_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     disc_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m args\u001b[38;5;241m.\u001b[39msave_file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnpi_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mparams_discco\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mdiscrim_coeff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_styco\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mstyle_coeff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_simco\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39msimilarity_coeff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_layers_5_11/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m npi_model, content_classifier_model, generation_classifier_model, avg_epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_adversarial_NPI\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/towards-neural-programming-interfaces/src/training/train_npi.py:356\u001b[0m, in \u001b[0;36mtrain_adversarial_NPI\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<<  NOTE :  ONLY FIRST \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m FILES IN DATA SET BEING USED  >>>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(num_pkls))\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m############################################################\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 356\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpu_num\u001b[49m))\n\u001b[1;32m    357\u001b[0m discrim_coeff \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mdiscrim_coeff\n\u001b[1;32m    358\u001b[0m style_coeff \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mstyle_coeff\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'gpu_num'"
     ]
    }
   ],
   "source": [
    "if train_npi:\n",
    "    args = Namespace(\n",
    "        save_file_path=npi_path,\n",
    "        train_file_path=data_path,\n",
    "        content_classifier_path=classifier_path+\"Classifier_classification_network_epoch50.bin\",\n",
    "        language_model_type=\"gpt2\",\n",
    "        npi_type=\"adversarial\",\n",
    "        content_classifier_type=\"pretrained\",\n",
    "        generation_classifier_type=\"adversarial\",\n",
    "        num_epochs=60,\n",
    "        batch_size=5,\n",
    "        test_freq=5,\n",
    "        save_freq=5,\n",
    "        num_pkls=35,\n",
    "        device=torch.device(\"cuda\"),\n",
    "        n_gpu = torch.cuda.device_count(),\n",
    "        gpu_num=0,\n",
    "        discrim_coeff=3.0,  #gamma\n",
    "        style_coeff=10.0,    #alpha\n",
    "        similarity_coeff=1.0, #beta\n",
    "        head_start_num=5,\n",
    "        perturbation_indices=[5,11],\n",
    "        max_seq_len=10,\n",
    "        num_seq_iters=10,\n",
    "        npi_lr=1e-4,\n",
    "        disc_lr=1e-4,\n",
    "    )\n",
    "    args.save_file_path=F\"{npi_path}params_discco{args.discrim_coeff}_styco{args.style_coeff}_simco{args.similarity_coeff}_layers_5_11/\"\n",
    "\n",
    "    npi_model, content_classifier_model, generation_classifier_model, avg_epoch_loss = train_adversarial_NPI(args)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b53feeeef0abc6b71390ce5a6fde0c401718055bbb2d86de1b9dab62a8ba524e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('towards-neural-programming-interfaces-UdnRbY7B': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
