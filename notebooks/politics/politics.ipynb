{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Notebook training NPI on political views\n",
    "\n",
    "This notebook is also a good example on how to use the NPI project to train your own NPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Prerequisites:\n",
    "\n",
    "* Follow the instructions in the readme to install the NPI repository before running this notebook.\n",
    "* Clone the [NewB repo](https://github.com/JerryWei03/NewB) in the data/external folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# For dev purposes, enable autoreload of modules\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "%autoreload\n",
    "\n",
    "# Constructing training dataset\n",
    "from npi.dataset import NPIDatasetConstructor, NPIDatasetLoader\n",
    "\n",
    "# Models\n",
    "from npi.models import NPITrainingModels\n",
    "\n",
    "# Training NPI\n",
    "from npi.training import NPIStyleTrainer, NPITrainer\n",
    "\n",
    "# Configuration\n",
    "from npi.config import NPIConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Notice that each step in training an NPI is conditioned on the variable toggles, so you can disable certain steps to not redo them again when running the whole notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggle steps\n",
    "construct = True\n",
    "train_class = True\n",
    "test_class = True\n",
    "train_npi = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layers = [5, 11]\n",
    "\n",
    "device = torch.device(f\"cuda:0\")\n",
    "config = NPIConfig(\n",
    "    device, gpt_model=\"gpt2\", perturbation_indices=model_layers, npi_name=\"politics\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset\n",
    "\n",
    "### Get Data from NewB GitHub repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `construct_politics_data` to see how to construct data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n",
      "gpu_device is cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8706/230710 [11:43<5:44:35, 10.74it/s]"
     ]
    }
   ],
   "source": [
    "if construct:\n",
    "    with open(\"../../data/external/NewB/train_orig.txt\", \"r\", newline=\"\") as f:\n",
    "        data = pd.read_csv(f, delimiter=\"\\t\", names=[\"view\", \"text\"])\n",
    "        data[\"view\"] = data[\"view\"].replace(\n",
    "            to_replace={0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1}\n",
    "        )\n",
    "        data = data[data.view != 5]\n",
    "        data = data.sample(frac=1)\n",
    "        data_iter = zip(data[\"text\"], data[\"view\"])\n",
    "        construct_data = NPIDatasetConstructor(config)\n",
    "        construct_data.construct_dataset(data_iter, len(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifier from Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier INIT\n",
      "Defining classifier model\n",
      "Loading style_model weights from models/npi_models/politics_style_model_008.pth\n",
      "Initializing class loss\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss=69986576.00 test_loss=72479288.00 test_accuracy=0.00:  33%|███▎      | 1/3 [00:00<00:00,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Style Classifier epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 5 train_loss=69986656.00 test_loss=72480176.00 test_accuracy=0.00:  33%|███▎      | 1/3 [00:00<00:00,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Style Classifier epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Style Classifier epoch 9\n",
      "Epoch train loss history ==  [69155562.66666667, 69155525.33333333, 69155517.33333333, 69155509.33333333, 69155496.0, 69155485.33333333, 69155477.33333333, 69155466.66666667, 69155456.0, 69155448.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model_loader = NPITrainingModels(config)\n",
    "dataset_loader = NPIDatasetLoader(config, target=\"style\")\n",
    "style_trainer = NPIStyleTrainer(config, class_lr=1e-5)\n",
    "classifier = None\n",
    "if train_class:\n",
    "    classifier = style_trainer.train_classifier(\n",
    "        model_loader,\n",
    "        dataset_loader,\n",
    "        num_epochs=10,\n",
    "        # continue_epoch=4,  # Set epoch of classifier to load to continue training.\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier INIT\n",
      "Defining classifier model\n",
      "Loading style_model weights from models/npi_models/politics_style_model_008.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(69738789.6, 0.44000000000000006)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, test_loader, _, _ = dataset_loader.load_train_and_test_dataloaders()\n",
    "\n",
    "classifier = model_loader.load_style_classifier() if not classifier else classifier\n",
    "# When output=True, it will log the following in models/npi_models/style_classifier_output.log:\n",
    "#   (generated text from the dataset)\n",
    "#   truth={target_label} actual={model_output}\n",
    "style_trainer.test_model(test_loader, classifier, torch.nn.BCELoss(), output=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training NPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models for training and testing\n",
    "models = NPITrainingModels(\n",
    "    config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 6\n",
    "split_ratio = 0.25\n",
    "batch_size = 5\n",
    "headstart = 0  # set at 0 for debugging\n",
    "\n",
    "if train_npi:\n",
    "    trainer = NPITrainer(config, batch_size=batch_size, headstart=headstart)\n",
    "    dataset_loader = NPIDatasetLoader(config, split_ratio=split_ratio)\n",
    "    trainer.train_adversarial_npi(models, num_epochs, dataset_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing GPT2WithNPI model with tokenizer -- not being placed on GPU until npi loss evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original GPT2 output: 'Trump today was found'\n",
      " to have been a liar.\n",
      "\n",
      "The FBI has been investigating the Trump campaign's ties to Russia.\n",
      "\n",
      "The Trump campaign has also been accused of using the word \"radical\" in a tweet.\n",
      "\n",
      "\"I am not a fan of the idea of a \"big-screen\" movie.\n",
      "\n",
      "\"I'm not going to say that I'm going to say that I'm going to say that I'm going to say that I'm going to say that I'm going to say that I'm going to say\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "text = \"Trump today was found\"\n",
    "print(F\"Original GPT2 output: '{text}'\\n{models.gpt2_generate_text(text)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPI INITIALIZATION\n",
      "Loading npi_model weights from models/npi_models/politics_npi_model_000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPI GPT2 output: 'Trump today was found'\n",
      " to have been a liar.\n",
      "\n",
      "The FBI has been investigating the Trump campaign's ties to Russia.\n",
      "\n",
      "The Trump campaign has also been accused of using the word \"radical\" in a tweet.\n",
      "\n",
      "\"I am not a racist, I am not a racist, I am not a racist, I am not a racist, I am not a racist, I am not a racist, I am not a racist, I am not a racist, I am not a racist, I am not a racist, I am\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "print(F\"NPI GPT2 output: '{text}'\\n{models.npi_generate_text(text)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b53feeeef0abc6b71390ce5a6fde0c401718055bbb2d86de1b9dab62a8ba524e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('towards-neural-programming-interfaces-UdnRbY7B': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
